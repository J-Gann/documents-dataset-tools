{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"target_country\": \"DE\",\n",
    "    \"digital_corpora_hosts_url\": \"https://digitalcorpora.s3.amazonaws.com/corpora/files/CC-MAIN-2021-31-PDF-UNTRUNCATED/metadata/cc-hosts-20230303.csv.gz\",\n",
    "    \"digital_corpora_provenance_url\": \"https://digitalcorpora.s3.amazonaws.com/corpora/files/CC-MAIN-2021-31-PDF-UNTRUNCATED/metadata/cc-provenance-20230303.csv.gz\",\n",
    "    \"max_workers\": 30,\n",
    "    \"max_pdf_pages\": 4,\n",
    "    \"max_pdf_size\": 5 * 1024 * 1024, # 5 MB,\n",
    "    \"timeout_seconds\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import gzip\n",
    "import tempfile\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import pymupdf\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tempfile import TemporaryDirectory\n",
    "import uuid\n",
    "import requests\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class NoKeyboardInterrupt:\n",
    "    \"\"\"Class to make operations uninterruptible\"\"\"\n",
    "    def __enter__(self):\n",
    "        self.original_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        signal.signal(signal.SIGINT, self.original_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RejectionReason(Enum):\n",
    "    TOO_MANY_PAGES = \"TOO_MANY_PAGES\"\n",
    "    TOO_LARGE = \"TOO_LARGE\"\n",
    "    CORRUPTED = \"CORRUPTED\"\n",
    "    TIMEOUT = \"TIMEOUT\"\n",
    "    OTHER = \"OTHER\"\n",
    "    ENCRYPTED = \"ENCRYPTED\"\n",
    "    NOT_FOUND = \"NOT_FOUND\"\n",
    "\n",
    "class DigitalCorporaDownloader:\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.digital_corpora_hosts = None\n",
    "        self.digital_corpora_provenance = None\n",
    "        self.rejected_pdf_urls = None\n",
    "        self.rejected_pdf_urls_lock = Lock()\n",
    "        self.accepted_pdf_urls = None\n",
    "        self.accepted_pdf_urls_lock = Lock()\n",
    "\n",
    "    def _download_and_extract_gz_file(self, url: str, local_path: Path):\n",
    "        with tempfile.NamedTemporaryFile(delete=True) as temp:\n",
    "            urlretrieve(url, temp.name)\n",
    "            with gzip.open(temp.name, 'rb') as f:\n",
    "                with open(local_path, 'wb') as f_out:\n",
    "                    f_out.write(f.read())\n",
    "\n",
    "\n",
    "    def _csv_to_dict(self, csv_path: Path):\n",
    "        parsed_hosts = {}\n",
    "        with csv_path.open(encoding='utf-8-sig') as f:\n",
    "            csv_reader = csv.reader(f)\n",
    "            header = next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                parsed_host = {}\n",
    "                for idx, head in enumerate(header):\n",
    "                    parsed_host[head] = row[idx]\n",
    "                parsed_hosts[parsed_host[\"url_id\"]] = parsed_host\n",
    "        return parsed_hosts\n",
    "\n",
    "    def _get_digital_corpora_hosts(self, local_path: Path = Path(\"hosts.csv\")):\n",
    "        if self.digital_corpora_hosts:\n",
    "            return self.digital_corpora_hosts\n",
    "\n",
    "        if not local_path.exists():\n",
    "            print(f\"Downloading hosts file to {local_path}\")\n",
    "            self._download_and_extract_gz_file(self.config[\"digital_corpora_hosts_url\"], local_path)\n",
    "\n",
    "        print(f\"Loading hosts from {local_path} ...\")\n",
    "        self.digital_corpora_hosts = self._csv_to_dict(local_path)\n",
    "        return self.digital_corpora_hosts\n",
    "\n",
    "    # TODO: Requires a lot of memory ( 25 GB )\n",
    "    def _get_digital_corpora_provenance(self, local_path: Path = Path(\"provenance.csv\")):\n",
    "        if self.digital_corpora_provenance:\n",
    "            return self.digital_corpora_provenance\n",
    "\n",
    "        if not local_path.exists():\n",
    "            print(f\"Downloading provenance file to {local_path}\")\n",
    "            self._download_and_extract_gz_file(self.config[\"digital_corpora_provenance_url\"], local_path)\n",
    "\n",
    "        print(f\"Loading provenance from {local_path} ...\")\n",
    "        self.digital_corpora_provenance = self._csv_to_dict(local_path)\n",
    "        return self.digital_corpora_provenance\n",
    "\n",
    "    def _filter_url_ids_by_country(self, hosts: dict, target_country: str):\n",
    "        filtered_hosts = []\n",
    "        for url_id, host in hosts.items():\n",
    "            if host[\"country\"] == target_country:\n",
    "                filtered_hosts.append(url_id)\n",
    "        return filtered_hosts\n",
    "\n",
    "    def filter_pdf_urls_by_country(self, target_country: str):\n",
    "        hosts = self._get_digital_corpora_hosts()\n",
    "        url_ids_for_target_country = self._filter_url_ids_by_country(hosts, target_country)\n",
    "\n",
    "        provenance = self._get_digital_corpora_provenance()\n",
    "        pdf_urls_for_target_country = []\n",
    "\n",
    "        for url_id in url_ids_for_target_country:\n",
    "            pdf_urls_for_target_country.append(provenance[url_id][\"url\"])\n",
    "        return pdf_urls_for_target_country\n",
    "\n",
    "    def _save_rejected_pdf_urls(self, file_path: Path = Path(\"rejected_pdf_urls.json\")):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(self.rejected_pdf_urls, f)\n",
    "\n",
    "    def _get_rejected_pdf_urls(self, file_path: Path = Path(\"rejected_pdf_urls.json\")):\n",
    "        if self.rejected_pdf_urls:\n",
    "            return self.rejected_pdf_urls\n",
    "\n",
    "        if not file_path.exists():\n",
    "            self.rejected_pdf_urls = {}\n",
    "            return self.rejected_pdf_urls\n",
    "        \n",
    "        with open(file_path, \"r\") as f:\n",
    "            self.rejected_pdf_urls = json.load(f)\n",
    "            return self.rejected_pdf_urls\n",
    "\n",
    "    def _save_accepted_pdf_urls(self, file_path: Path = Path(\"accepted_pdf_urls.json\")):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(self.accepted_pdf_urls, f)\n",
    "\n",
    "    def _get_accepted_pdf_urls(self, file_path: Path = Path(\"accepted_pdf_urls.json\")):\n",
    "        if self.accepted_pdf_urls:\n",
    "            return self.accepted_pdf_urls\n",
    "\n",
    "        if not file_path.exists():\n",
    "            self.accepted_pdf_urls = {}\n",
    "            return self.accepted_pdf_urls\n",
    "        \n",
    "        with open(file_path, \"r\") as f:\n",
    "            self.accepted_pdf_urls = json.load(f)\n",
    "            return self.accepted_pdf_urls\n",
    "\n",
    "    def _validate_pdf(self, url: str, pdf_path: Path, target_folder: Path):\n",
    "        # check if pdf can be opened by pymupdf\n",
    "        try:\n",
    "            pdf = pymupdf.open(pdf_path)\n",
    "        except Exception as e:\n",
    "            self._reject_pdf(url, pdf_path, RejectionReason.CORRUPTED)\n",
    "            return False\n",
    "        \n",
    "        # check if pdf is encrypted\n",
    "        if pdf.is_encrypted:\n",
    "            self._reject_pdf(url, pdf_path, RejectionReason.ENCRYPTED)\n",
    "            return False\n",
    "        \n",
    "        # check if pdf has less than 4 pages\n",
    "        if pdf.page_count > self.config[\"max_pdf_pages\"]:\n",
    "            self._reject_pdf(url, pdf_path, RejectionReason.TOO_MANY_PAGES)\n",
    "            return False\n",
    "        \n",
    "        # check if pdf file size is too large\n",
    "        if os.path.getsize(pdf_path) > self.config[\"max_pdf_size\"]:\n",
    "            self._reject_pdf(url, pdf_path, RejectionReason.TOO_LARGE)\n",
    "            return False\n",
    "        \n",
    "        self._accept_pdf(url, pdf_path, target_folder)\n",
    "        return True\n",
    "\n",
    "    def _reject_pdf(self, url: str, pdf_path: Path, reason: RejectionReason):\n",
    "        with self.rejected_pdf_urls_lock:\n",
    "            self.rejected_pdf_urls[url] = reason.value\n",
    "            # Temporary file is automatically deleted using tmp folder\n",
    "\n",
    "    def _accept_pdf(self, url: str, pdf_path: Path, target_folder: Path):\n",
    "        with self.accepted_pdf_urls_lock:\n",
    "            #with NoKeyboardInterrupt():\n",
    "            # This operation should not be interrupted in order to avoid\n",
    "            # a mismatch between the accepted_pdf_urls.json and the\n",
    "            # actual pdf files\n",
    "            pdf_index = len(self.accepted_pdf_urls)\n",
    "            shutil.copy(pdf_path, target_folder / f\"{pdf_index}.pdf\")\n",
    "            # TODO: If interrupted here, the pdf will be downloaded again with a different name leading to a duplicate\n",
    "            self.accepted_pdf_urls[url] = f\"{pdf_index}.pdf\"\n",
    "\n",
    "    def _download_pdf(self, url: str, output_path: Path):\n",
    "        response = requests.get(url, timeout=self.config[\"timeout_seconds\"], stream=True)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(output_path, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    pdf_file.write(chunk)\n",
    "\n",
    "    def _download_pdf_worker(self, url: str, target_folder: Path):\n",
    "        target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Check if url is already accepted (downloaded and successfully validated)\n",
    "        accepted_pdf_urls = self._get_accepted_pdf_urls()\n",
    "        if url in accepted_pdf_urls:\n",
    "            return\n",
    "        \n",
    "        # check if url is already rejected (downloaded but not successfully validated)\n",
    "        rejected_pdf_urls = self._get_rejected_pdf_urls()\n",
    "        if url in rejected_pdf_urls:\n",
    "            return\n",
    "        \n",
    "        # download pdf to tmp folder\n",
    "        with TemporaryDirectory() as tmp_folder:\n",
    "            tmp_folder_path = Path(tmp_folder)\n",
    "            pdf_path = tmp_folder_path / (str(uuid.uuid4()) + \".pdf\")\n",
    "\n",
    "            try:\n",
    "                self._download_pdf(url, pdf_path)\n",
    "            except Exception as e:\n",
    "                if isinstance(e, requests.exceptions.Timeout):\n",
    "                    self._reject_pdf(url, pdf_path, RejectionReason.TIMEOUT)\n",
    "                else:\n",
    "                    self._reject_pdf(url, pdf_path, RejectionReason.NOT_FOUND)\n",
    "                return\n",
    "            \n",
    "            # copies the pdf file to the target folder if it meets the criteria\n",
    "            self._validate_pdf(url, pdf_path, target_folder)\n",
    "        return True\n",
    "\n",
    "    def download_pdfs(self, urls: list[str], target_folder: Path = Path(\"pdfs\")):\n",
    "        with ThreadPoolExecutor(max_workers=self.config[\"max_workers\"]) as executor:\n",
    "            futures = [executor.submit(self._download_pdf_worker, url, target_folder) for url in urls]\n",
    "            pbar = tqdm(as_completed(futures), total=len(futures))\n",
    "            for future in pbar:\n",
    "                future.result()\n",
    "\n",
    "        self._save_accepted_pdf_urls()\n",
    "        self._save_rejected_pdf_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = DigitalCorporaDownloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hosts from hosts.csv ...\n",
      "Loading provenance from provenance.csv ...\n"
     ]
    }
   ],
   "source": [
    "urls = downloader.filter_pdf_urls_by_country(\"DE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c289596d8e47e1a186fbbab3186ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downloader.download_pdfs(urls[:10000], Path(\"pdfs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downloader.rejected_pdf_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downloader.accepted_pdf_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
